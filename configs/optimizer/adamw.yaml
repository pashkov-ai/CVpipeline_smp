_target_: torch.optim.AdamW
lr: ${general.learning_rate}
#betas: (0.9, 0.999)
eps: 1e-08
weight_decay: 0.01
amsgrad: False
maximize: False
capturable: False
differentiable: False
#foreach: None
#fused: None
